{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New evaluation codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import exists\n",
    "\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 10:00:46.649 | INFO     | experiments:get_samplers:269 - Loaded /Users/joewandy/Work/git/vimms-gym/pickles/samplers_QCB_small_gaussian.p\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'chemical_creator': {'mz_range': (100, 110),\n",
       "   'rt_range': (400, 500),\n",
       "   'intensity_range': (10000.0, 1e+20),\n",
       "   'n_chemicals': (20, 50),\n",
       "   'mz_sampler': <vimms.ChemicalSamplers.MZMLFormulaSampler at 0x7fdfec0bce80>,\n",
       "   'ri_sampler': <vimms.ChemicalSamplers.MZMLRTandIntensitySampler at 0x7fdfed043dc0>,\n",
       "   'cr_sampler': <vimms.ChemicalSamplers.GaussianChromatogramSampler at 0x7fdfed065760>},\n",
       "  'noise': {'enable_spike_noise': True,\n",
       "   'noise_density': 0.1,\n",
       "   'noise_max_val': 1000.0,\n",
       "   'mz_range': (100, 110)},\n",
       "  'env': {'ionisation_mode': 'Positive',\n",
       "   'rt_range': (400, 500),\n",
       "   'isolation_window': 0.7,\n",
       "   'mz_tol': 10,\n",
       "   'rt_tol': 120,\n",
       "   'alpha': 0.191500954,\n",
       "   'beta': 0.030798858}},\n",
       " 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiments import preset_qcb_small\n",
    "alpha = 0.191500954\n",
    "beta = 0.030798858\n",
    "extract = False\n",
    "params, max_peaks = preset_qcb_small(None, alpha=alpha, beta=beta, extract_chromatograms=extract)\n",
    "params, max_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vimms_gym.env import DDAEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from vimms.Evaluation import EvaluationData\n",
    "from vimms_gym.common import EVAL_METRIC_REWARD\n",
    "from vimms_gym.evaluation import evaluate\n",
    "from tune import TrialEvalCallback\n",
    "\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/vimms-gym/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:561: UserWarning:\n",
      "\n",
      "This system does not have apparently enough memory to store the complete replay buffer 9.87GB > 0.35GB\n",
      "\n",
      "/opt/anaconda3/envs/vimms-gym/lib/python3.9/site-packages/stable_baselines3/dqn/dqn.py:152: UserWarning:\n",
      "\n",
      "The number of environments used is greater than the target network update interval (20 > 1), therefore the target network will be updated after each call to env.step() which corresponds to 20 steps.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_objects = {\n",
    "    \"learning_rate\": 0.0,\n",
    "    \"lr_schedule\": lambda _: 0.0,\n",
    "    \"clip_range\": lambda _: 0.0,\n",
    "}    \n",
    "\n",
    "fname = os.path.join('..', 'DQN', 'DQN_9.zip') \n",
    "model = DQN.load(fname, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<vimms_gym.env.DDAEnv at 0x7fdfec0bc6a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_env = DDAEnv(max_peaks, params)\n",
    "eval_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ionisation_mode': 'Positive',\n",
       "  'rt_range': (400, 500),\n",
       "  'isolation_window': 0.7,\n",
       "  'mz_tol': 10,\n",
       "  'rt_tol': 120,\n",
       "  'alpha': 0.191500954,\n",
       "  'beta': 0.030798858},\n",
       " 0.191500954,\n",
       " 0.030798858)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_env.env_params, eval_env.alpha, eval_env.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Monitor<DDAEnv instance>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_env = Monitor(eval_env)\n",
    "eval_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = EVAL_METRIC_REWARD\n",
    "eval_callback = TrialEvalCallback(eval_env, None, eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_episodes = 1\n",
    "verbose = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv at 0x7fe00a6868e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = eval_callback.eval_env\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deterministic = eval_callback.deterministic\n",
    "# deterministic = True\n",
    "deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_count = 0\n",
    "episode_count_target = n_eval_episodes\n",
    "current_reward = 0\n",
    "current_length = 0\n",
    "observations = env.reset()\n",
    "states = None\n",
    "episode_starts = np.ones((env.num_envs,), dtype=bool)\n",
    "episode_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation episode 0 finished: metric -499.000000, timedelta=0:00:00.310517\n"
     ]
    }
   ],
   "source": [
    "episode_rewards = []\n",
    "episode_eval_results = []\n",
    "episode_lengths = []\n",
    "start = timer()\n",
    "while episode_count < episode_count_target:\n",
    "    actions, states = model.predict(observations, state=states,\n",
    "                                    episode_start=episode_starts,\n",
    "                                    deterministic=deterministic)\n",
    "    observations, rewards, dones, infos = env.step(actions)\n",
    "    # print(rewards, current_reward, current_length, dones)\n",
    "    episode_starts = dones\n",
    "    current_reward += rewards[0]\n",
    "    current_length += 1\n",
    "\n",
    "    if dones[0]:  # when done, episode would be reset automatically\n",
    "        val = current_reward\n",
    "        eval_res = evaluate(eval_data, format_output=False)\n",
    "        episode_eval_results.append(eval_res)\n",
    "        if verbose > 0:\n",
    "            end = timer()\n",
    "            print('Evaluation episode %d finished: metric %f, timedelta=%s' % (\n",
    "                episode_count, val, str(timedelta(seconds=end - start))))\n",
    "            start = timer()\n",
    "        episode_rewards.append(val)\n",
    "        episode_lengths.append(current_length)\n",
    "        episode_count += 1\n",
    "        current_reward = 0\n",
    "        current_length = 0\n",
    "\n",
    "    # store previous results for evaluation before 'done'\n",
    "    # this needs to be here, because VecEnv is automatically reset when done\n",
    "    inner_env = env.envs[0].env\n",
    "    eval_data = EvaluationData(inner_env.vimms_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-499.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-499.0, 0.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(episode_rewards), np.std(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = [e['coverage_prop'] for e in episode_eval_results]\n",
    "np.mean(metric), np.std(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = [e['intensity_prop'] for e in episode_eval_results]\n",
    "np.mean(metric), np.std(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = [e['f1'] for e in episode_eval_results]\n",
    "np.mean(metric), np.std(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7791ce17e478d6b0fb6b31f66d51580be045b7d8633e3f5b85f8af4f319f0917"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
